---
layout: default
title: spark初识
---
<h2>{{page.title}}</h2>
<div>这是spark学习笔记的一篇文章，通过对spark论文的解读，是大家对于spark的整体架构有一个大致的了解。</div>
<hr/>
<div>在spark没有诞生之前，在集群上对于大数据的处理方式一般是MapReduce，但后者的处理方式有一个缺陷就是每次处理过后的数据都会被放入磁盘中，这就使得像机器学习这种需要对数据进行大量迭代处理的应用很难在保证处理速度的情况下使用MapReduce框架（大量的磁IO操作）。这就是spark诞生的原因，spark在保留了MapReduce的优点（大规模操作、高容错性）的前提下，高度优化了迭代操作的处理方式。</div>
<div>为达到这一目标，spark提出了一种称为弹性数据集（RDD）的数据抽象。RDD是一中可以将数据集以Partition的形式放置在不同节点上的只读集合。同时，在某一个Partition丢失的情况下，还可以根据RDD之间的依赖进行重构，保证了高容错性。spark使用scala语言编写，但对python、java以及R语言都有很好的支持。</div>
<div>spark的编程模型</div>
<hr>
<div>弹性数据集RDD</div>
<div>如前文所说，弹性数据集RDD是spark对于我们要处理的数据的一个抽象类型。RDD元素并不一定真实存在与物理内存之中，应用也就是我们对于数据的处理算子会被记录下来，这样的一个好处就是在RDD出现某个一部分丢失的情况时，我们可以通过这些被记录下来的处理算子对RDD进行重建。这也是spark高容错性的表现。</div>
<div>spark允许用户用四种方式生成RDD：1、从像HDFGS这样的分布式文件系统中读取文件生成RDD。2、使用“parallelize”算子在内存中生成RDD（前提是这个RDD要小于spark所能使用的内存）。3、对于已存在的 RDD通过转化操作（transform系列算子）生成新的RDD。4、使用“persist”或“cache”算子实例化一个RDD（前提是内存足够，否则spark会在下次用到这个RDD时重新计算它，最新的spark采用memory-disk-trade off的方式让用户可以设定实例化RDD是存在于内存之中还是部分存在于内存之中）。</div>
<div>RDD的并行化操作</div>
<div>RDD的操作算子可分为两种，生成新的RDD的transform操作和生成计算结果的action操作。如前文所说,RDD并不需要真实存储。RDD的transform操作都是lazy的，也就是说spark在读取到用户对RDD的转化操作后并不会立马执行来生成新的RDD，而是会把这个操作的相关信息记录下来，直到spark读取到对RDD的action操作时，才会触发之前的transform操作。这样不仅提高了容错性，同时也节省了大量的IO操作。
</div>
<div>spark通常是运行在集群上的，用户程序对于RDD的操作是通过序列化传送到工作节点上运行的。这种序列化到工作节点上的函数都是闭包，这就导致如果用户程序之中定义的全局变量不会起作用。针对这一情况，spark定义了两种特殊的共享变量--广播变量（Broadcast variables）和累加器（Accumulators）。广播变量是一个会随用户程序序列化到工作节点的一个只读变量，设想一下，如果有一个很大的数据在每一次并行操作的时候都会用到，如果每次操作都序列化它，然后传给工作节点就会造成浪费。广播变量的用处就是一次传给工作节点后，就持续存在与工作节点的内存之中。累加器变量是一种工作节点只能进行加操作，而客户端只读的变量。起到计数的作用</div>
<div>以上就是spark的一些重要特性的介绍，对于spark的详细工作流程会在今后的文章中介绍。</div>